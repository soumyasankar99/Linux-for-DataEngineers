
![Linux for](https://github.com/user-attachments/assets/81b5431c-bbc4-4b11-be69-853c2b96f3cb)

# Linux Zero to Hero for Data Engineering üöÄ

Welcome to the **Linux Zero to Hero for Data Engineering** repository! This guide is designed to empower data engineers by teaching essential Linux skills for managing data, automating ETL workflows, batch processing, and real-time streaming automation.

## üìñ What You'll Learn
This repository takes you from the basics of Linux to advanced data engineering applications, including:
- Core Linux commands and utilities specifically useful for data manipulation
- How to batch process large datasets efficiently with Linux
- Automating ETL processes and scheduling tasks with Cron jobs
- Real-time streaming data automation for continuous data workflows

## üõ†Ô∏è Roadmap to Linux Mastery in Data Engineering

1. **Foundation**: Learn essential Linux commands for managing files, directories, and access controls.
2. **Data Manipulation and Management**: Gain expertise in manipulating and filtering data using Linux.
3. **Batch Processing and Automation**: Automate ETL workflows, schedule tasks with Cron, and learn error handling.
4. **Streaming Automation**: Set up real-time data pipelines, process logs, and monitor performance.
5. **ETL and Data Engineering Projects**: Build full-fledged data engineering pipelines from extraction to loading.

## üìù Table of Contents
- [Foundation](./Foundation)
- [Data Manipulation and Management](./Data-Manipulation-and-Management)
- [Batch Processing and Automation](./Batch-Processing-and-Automation)
- [Streaming Automation](./Streaming-Automation)
- [ETL and Data Engineering Projects](./ETL-and-Data-Engineering-Projects)
- [Resources and Useful Links](#resources-and-useful-links)

## üóÇÔ∏è Getting Started

1. **Clone the Repo**: `git clone https://github.com/soumyasankar99/Linux-Zero-to-Hero-for-Data-Engineering.git`
2. **Navigate the Folders**: Each folder corresponds to a section in the roadmap.
3. **Start Learning!** Begin with the foundation section and follow through the topics step-by-step.

## üåü Real-World Examples

- **Batch ETL with Cron**: Create a daily job that extracts data from logs, transforms it with Bash commands, and loads it into a database.
- **Streaming Automation**: Build a listener using Linux tools to automate log capturing and processing for real-time analytics.
- **Project-based Learning**: End-to-end ETL pipeline automation for real-world data engineering workflows.

## üîß Example Project: Automating ETL with Bash and Cron
In the "Projects" folder, you‚Äôll find a sample ETL job using Bash and Cron to:
- Extract raw data files
- Transform the data using text processing utilities
- Load the final output into a MySQL database or export to S3

## üìö Resources and Useful Links

Here are some curated resources to help you deepen your Linux and data engineering knowledge:

### Beginner Linux Learning
- [Linux Journey](https://linuxjourney.com/) - Free, beginner-friendly courses on Linux fundamentals.
- [Learn Linux Command Line](https://www.learnlinuxcommand.org/) - An interactive resource for learning essential commands.
- [The Linux Command Line Book](https://linuxcommand.org/tlcl.php) - A free PDF book for diving deeper into Linux CLI.

### Linux for Data Engineering
- [Data Wrangling with Bash](https://www.dataquest.io/blog/data-wrangling-with-bash/) - A guide to using Bash for data manipulation tasks.
- [Linux Shell Scripting Tutorial](https://bash.cyberciti.biz/guide/Main_Page) - Covers scripting techniques that can be applied in ETL and automation tasks.
- [AWK for Data Analysis](https://www.datacamp.com/community/tutorials/awk-tutorial-grep) - Introduction to `awk` for processing structured data.

### Bash Scripting and Automation
- [Bash Scripting Cheatsheet](https://devhints.io/bash) - A concise reference for scripting essentials.
- [Advanced Bash-Scripting Guide](https://tldp.org/LDP/abs/html/) - Comprehensive guide to advanced Bash scripting techniques.
- [Scheduling Cron Jobs](https://opensource.com/article/17/11/how-use-cron-linux) - Basics of Cron jobs and task automation.

### ETL and Data Processing
- [ETL with Shell Scripts](https://medium.com/@abhaykumar007/etl-using-shell-scripting-daf2c85fb4f8) - Hands-on example of creating ETL pipelines with shell scripts.
- [Big Data with Linux Tools](https://www.linux.com/learn/tutorials/managing-big-data-on-linux) - Using Linux tools for handling big data in production environments.
- [Regular Expressions 101](https://regex101.com/) - An interactive tool to learn and test regular expressions, critical for data extraction.

### Streaming and Real-Time Data
- [Getting Started with Kafka](https://kafka.apache.org/quickstart) - Guide to Kafka, a powerful tool for real-time streaming.
- [Streaming Data with Linux and Netcat](https://blog.revolutionanalytics.com/2014/10/real-time-data-streaming-in-r-using-netcat.html) - Example of using `netcat` for streaming data simulation.
- [Building Real-Time Data Pipelines](https://towardsdatascience.com/real-time-data-pipeline-a-deep-dive-46b77e8e5027) - Concepts and architecture of real-time pipelines.

### Online Communities and Forums
- [Linux Stack Exchange](https://unix.stackexchange.com/) - Q&A forum for all Linux-related queries.
- [Data Engineering Subreddit](https://www.reddit.com/r/dataengineering/) - Discussion platform for data engineering professionals.
- [Linux Foundation Training](https://training.linuxfoundation.org/) - Offers courses on Linux fundamentals and system administration.

## üì¨ Contribution Guide

We welcome contributions! Here‚Äôs how to get started:
- Fork the repository.
- Create a new branch for your changes.
- Submit a pull request with a clear description of the changes.

## üì¢ Feedback
We‚Äôd love to hear from you! Open an issue or submit a pull request if you have ideas for improvement.

**Happy Learning and Data Engineering with Linux!**

